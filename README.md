<div align="right">
  <a href="README_EN.md">ğŸŒ English Version</a>
</div>

# ğŸš€FastGPT-vLLM-Qwen-TEIå…¨é“¾è·¯æœ¬åœ°åŒ–éƒ¨ç½²

> åŸºäºvLLM(Qwen2.5)çš„FastGPTé«˜æ€§èƒ½ç§æœ‰RAGçŸ¥è¯†åº“å’ŒFrp+Nginxå…¬ç½‘è®¿é—®çš„ä¸€ç«™å¼éƒ¨ç½²æ–¹æ¡ˆã€‚
> ä¸“ä¸ºå›½å†…å†…ç½‘ç¯å¢ƒä¼˜åŒ–ï¼Œè§£å†³HuggingFaceä¸‹è½½ã€Dockeré•œåƒåŠ é€ŸåŠæ˜¾å­˜OOMç­‰ç—›ç‚¹ã€‚

![FastGPT](https://img.shields.io/badge/FastGPT-v4.x-blue)
![vLLM](https://img.shields.io/badge/vLLM-0.6.x-green)
![Qwen](https://img.shields.io/badge/Model-Qwen2.5--7B-violet)
![TEI](https://img.shields.io/badge/Embedding-BGE--M3-orange)

## ğŸ“– é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æä¾›äº†ä¸€å¥—å®Œæ•´çš„FastGPTæœ¬åœ°åŒ–éƒ¨ç½²å®æˆ˜æŒ‡å—ï¼ŒåŸºäºvLLMï¼ˆæ¨ç†åŠ é€Ÿï¼‰å’ŒTEIï¼ˆå‘é‡åŠ é€Ÿï¼‰æ„å»ºï¼Œå……åˆ†å‘æŒ¥å•å¡æ˜¾å­˜æ€§èƒ½ï¼Œå®ç°é«˜å¹¶å‘ã€ä½å»¶è¿Ÿçš„çŸ¥è¯†åº“é—®ç­”ã€‚

### æ ¸å¿ƒç‰¹æ€§
- ğŸ‡¨ğŸ‡³ **å›½å†…ç½‘ç»œä¼˜åŒ–**ï¼šæä¾›HuggingFaceé•œåƒä¸‹è½½ã€Dockeré•œåƒä»£ç†é…ç½®å…¨æµç¨‹ã€‚
- âš¡ **é«˜æ€§èƒ½æ¨ç†**ï¼šä½¿ç”¨vLLMéƒ¨ç½²Qwen2.5-7Bï¼Œä½¿ç”¨TEIéƒ¨ç½²BGE-M3ã€‚
- ğŸ’¾ **æ˜¾å­˜ç²¾ç»†ç®¡ç†**ï¼šé€šè¿‡å‚æ•°è°ƒä¼˜ï¼Œå®ç°LLMä¸Embeddingæ¨¡å‹åœ¨å•å¡æ˜¾å­˜ä¸‹çš„ç¨³å®šå…±å­˜ã€‚
- ğŸŒ **å…¬ç½‘è®¿é—®**ï¼šé›†æˆFRP + Nginxæ–¹æ¡ˆï¼Œå®ç°å†…ç½‘æœåŠ¡çš„å…¬ç½‘å®‰å…¨è®¿é—®ã€‚

## ğŸ› ï¸ æŠ€æœ¯æ ˆ
- **åº”ç”¨å±‚**ï¼šFastGPT + MongoDB + PostgreSQL(pgvector)
- **æ¨ç†å±‚**ï¼švLLM(Qwen2.5-7B-Instruct)
- **ç´¢å¼•å±‚**ï¼šText Embeddings Inference(BAAI/bge-m3)
- **ç½‘ç»œå±‚**ï¼šFRP(å†…ç½‘ç©¿é€) + Nginx(åå‘ä»£ç†)
- **å®¹å™¨åŒ–**ï¼šDocker & Docker Compose

## âš¡ å¿«é€Ÿå¼€å§‹

## 1. ç¯å¢ƒæ­å»º
ä»¥ä¸‹æ˜¯æˆ‘ä¸ªäººéƒ¨ç½²çš„æœºå™¨é…ç½®å’Œç¯å¢ƒï¼š
- Ubuntu 22.04
- CUDA 12.1
- RTX3090-24GB
- Python3.10
- Docker 28.2.2
- Dcoker Compose 2.20.3

### 1.1 å®‰è£…NVIDIAé©±åŠ¨ä¸CUDA
ç¡®ä¿`nvidia-smi`å¯ä»¥æ­£å¸¸è¾“å‡ºæ˜¾å¡ä¿¡æ¯ã€‚æ¨èå®‰è£…CUDA 12.1æˆ–ä»¥ä¸Šç‰ˆæœ¬ã€‚
è¯¦ç»†çš„å®‰è£…æ•™ç¨‹å¯ä»¥è‡ªè¡Œæœç´¢ï¼Œæœ¬é¡¹ç›®ä¸è¿‡å¤šä»‹ç»ã€‚

### 1.2 å®‰è£…Dockerä¸NVIDIA Container Toolkit
- æ³¨æ„ï¼šå¿…é¡»å®‰è£…`NVIDIA Container Toolkit`ï¼Œå¦åˆ™Dockerå®¹å™¨æ— æ³•è°ƒç”¨æ˜¾å¡ã€‚

```bash
# 1. å®‰è£…Docker
curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun
systemctl enable --now docker

curl -L https://github.com/docker/compose/releases/download/v2.20.3/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose

# éªŒè¯å®‰è£…
docker -v
docker-compose -v
# å¦‚å¤±æ•ˆï¼Œå¯ä»¥é—®AIè§£å†³ä¸‹~

# 2. é…ç½®å›½å†…é•œåƒæº(å…³é”®ï¼šJSONæ•°ç»„æœ«å°¾ä¸¥ç¦é€—å·)
sudo tee /etc/docker/daemon.json <<EOF
{
    "registry-mirrors": [
        "[https://docker.nju.edu.cn](https://docker.nju.edu.cn)",
        "[https://docker.m.daocloud.io](https://docker.m.daocloud.io)"
    ]
}
EOF

# 3. å®‰è£…NVIDIA Container Toolkit
sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo nvidia-ctk runtime configure --runtime=docker

# 4. é‡å¯Docker
sudo systemctl daemon-reload
sudo systemctl restart docker
```

###1.3 å®‰è£…Pythonç¯å¢ƒ
- æ³¨æ„ï¼šæœ¬é¡¹ç›®ä½¿ç”¨çš„æ˜¯`Miniforge`å®‰è£…çš„è™šæ‹Ÿç¯å¢ƒï¼Œå½“ç„¶ä½ ä¹Ÿå¯ä»¥ä¸ç”¨è™šæ‹Ÿç¯å¢ƒï¼Œç”¨ä½ è‡ªå·±çš„æœ¬åœ°Pythonç¯å¢ƒä¹Ÿè¡Œï¼Œè‡ªè¡Œé€‰æ‹©~
```bash
# åˆ›å»ºå¹¶æ¿€æ´»ç¯å¢ƒ
conda create -n llm python=3.10
conda activate llm

# å®‰è£…ä¾èµ–
pip install vllm huggingface_hub
```

## 2. æ¨¡å‹ä¸‹è½½

```bash
pip install huggingface_hub
export HF_ENDPOINT=https://hf-mirror.com

# Qwen2.5, å°†'/your/path/'åˆ‡æ¢æˆä½ æƒ³è¦ä¸‹è½½çš„è·¯å¾„
huggingface-cli download --resume-download Qwen/Qwen2.5-7B-Instruct \
  --local-dir /your/path/Qwen2.5 

# BGE-M3, å°†'/your/path/'åˆ‡æ¢æˆä½ æƒ³è¦ä¸‹è½½çš„è·¯å¾„
huggingface-cli download --resume-download BAAI/bge-m3 \
  --local-dir /your/path/bge-m3 \
  --exclude "*.DS_Store"
```

## 3.å¯åŠ¨æœ¬åœ°æ¨¡å‹æœåŠ¡
### 3.1å¯åŠ¨vLLM(Qwen2.5)
- æ³¨æ„ï¼šæœ¬é¡¹ç›®ä¸ºäº†ä¿è¯å•å¡24Gæ˜¾å­˜èƒ½å¤ŸåŒæ—¶è¿è¡ŒEmbeddingæ¨¡å‹ï¼Œæˆ‘å°†vLLMçš„æ˜¾å­˜åˆ©ç”¨ç‡ä¸¥æ ¼é™åˆ¶åœ¨80%ï¼Œå®é™…å¯æ ¹æ®è‡ªå·±æ˜¾å¡çš„æ˜¾å­˜æ¥è°ƒæ•´è¿™ä¸ªæ¯”ä¾‹ã€‚
- `--served-model-name Qwen2.5`: å…³é”®å‚æ•°ï¼Œå¼ºåˆ¶æŒ‡å®šæ¨¡å‹åç§°ï¼Œé˜²æ­¢FastGPTæŠ¥é”™404ã€‚
- `--gpu-memory-utilization 0.8`: é¢„ç•™çº¦20%æ˜¾å­˜ç»™TEIæ¨¡å‹ä½¿ç”¨ã€‚
```bash
# å°†/your/path/Qwen2.5æ›¿æ¢ä¸ºåˆšåˆšä¸‹è½½å¥½çš„æ¨¡å‹è·¯å¾„
python -m vllm.entrypoints.openai.api_server \
    --model /your/path/Qwen2.5 \
    --served-model-name Qwen2.5 \
    --max-model-len 8192 \
    --gpu-memory-utilization 0.8 \
    --port 8000 \
    --host 0.0.0.0 \
    --api-key sk-123456
```

### 3.2 å¯åŠ¨TEI(BGE-M3)
- æ³¨æ„ï¼šæœ¬é¡¹ç›®ä½¿ç”¨DockeræŒ‚è½½æœ¬åœ°æ¨¡å‹ç›®å½•ï¼Œå½»åº•è§„é¿å®¹å™¨å†…ä¸‹è½½å¤±è´¥çš„é—®é¢˜ã€‚
```bash
# å°†/your/path/bge-m3æ›¿æ¢ä¸ºåˆšåˆšä¸‹è½½å¥½çš„æ¨¡å‹è·¯å¾„
# ä½¿ç”¨m.daocloud.ioä»£ç†ghcr.ioé•œåƒ
sudo docker run --gpus all -d --name tei-bge \
    -p 8008:80 \
    -v /your/path/bge-m3:/data \
    m.daocloud.io/ghcr.io/huggingface/text-embeddings-inference:latest \
    --model-id /data
```

## 4.éƒ¨ç½²FastGPT
### 4.1 åˆ›å»ºç›®å½•ä¸æ‹‰å–é…ç½®æ–‡ä»¶
- ä»¥ä¸‹ä¸¤ä¸ªé•œåƒè‡ªè¡Œé€‰æ‹©ä¸‹è½½,è‹¥æ— æ³•ä¸‹è½½å¯ä»¥åœ¨æœ¬ä»“åº“ä¸­æ‰‹åŠ¨ä¸‹è½½ã€‚
- `docker-compose.yml`å’Œ`config.json`æ–‡ä»¶æˆ‘å·²ç»ä¸Šä¼ åœ¨æœ¬ä»“åº“äº†ã€‚
```bash
# å›½å†…é•œåƒ(é˜¿é‡Œäº‘)
bash <(curl -fsSL https://doc.fastgpt.cn/deploy/install.sh) --region=cn --vector=pg

# éå›½å†…é•œåƒ(dockhub, ghcr)
bash <(curl -fsSL https://doc.fastgpt.cn/deploy/install.sh) --region=global --vector=pg
```

### 4.2 ä¿®æ”¹é…ç½®æ–‡ä»¶(å¯é€‰)
- é€šå¸¸æƒ…å†µä¸‹ï¼Œ`docker-compose.yml`æ— éœ€ä¿®æ”¹ã€‚å¦‚æœç«¯å£å†²çªï¼Œå¯ä¿®æ”¹`ports`æ˜ å°„ã€‚
- `config.json`ç”¨äºç³»ç»Ÿçº§é…ç½®ï¼Œå»ºè®®ä¿æŒé»˜è®¤ï¼Œæ¨¡å‹é…ç½®æˆ‘ä»¬åœ¨Webç•Œé¢è¿›è¡Œã€‚

### 4.3 å¯åŠ¨FastGPT
```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡(Mongo, Postgres, FastGPT, OneAPI)
docker-compose up -d
```
- è®¿é—®åœ°å€ï¼š`http://localhost:3000`(é»˜è®¤è´¦å·:`root`, å¯†ç :`docker-compose.yml`é‡Œçš„`DEFAULT_ROOT_PSW`)
- å®˜æ–¹é»˜è®¤å¯†ç æˆ‘è®°å¾—æ˜¯`1234`
