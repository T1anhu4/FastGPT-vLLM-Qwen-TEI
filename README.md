# FastGPT-vLLM-Qwen-TEI
An end-to-end deployment solution for a high-performance private RAG knowledge base powered by FastGPT with vLLM (Qwen2.5), combined with public access via FRP and Nginx.
åŸºäºvLLM(Qwen2.5)çš„FastGPTé«˜æ€§èƒ½ç§æœ‰RAGçŸ¥è¯†åº“å’ŒFrp+Nginxå…¬ç½‘è®¿é—®çš„ä¸€ç«™å¼éƒ¨ç½²æ–¹æ¡ˆã€‚


<div align="right">
  <a href="README_EN.md">ğŸŒ English Version</a>
</div>

# ğŸš€ FastGPT + vLLM å…¨é“¾è·¯æœ¬åœ°åŒ–éƒ¨ç½²æŒ‡å—

> åŸºäº Ubuntu + å•å¡ 24G æ˜¾å­˜çš„ä¼ä¸šçº§çŸ¥è¯†åº“ç§æœ‰åŒ–æ–¹æ¡ˆã€‚
> ä¸“ä¸ºå›½å†…å†…ç½‘ç¯å¢ƒä¼˜åŒ–ï¼Œè§£å†³ HuggingFace ä¸‹è½½ã€Docker é•œåƒåŠ é€ŸåŠæ˜¾å­˜ OOM ç­‰ç—›ç‚¹ã€‚

![FastGPT](https://img.shields.io/badge/FastGPT-v4.x-blue)
![vLLM](https://img.shields.io/badge/vLLM-0.6.x-green)
![Qwen](https://img.shields.io/badge/Model-Qwen2.5--7B-violet)
![TEI](https://img.shields.io/badge/Embedding-BGE--M3-orange)

## ğŸ“– é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æä¾›äº†ä¸€å¥—å®Œæ•´çš„ FastGPT æœ¬åœ°åŒ–éƒ¨ç½²å®æˆ˜æŒ‡å—ï¼ŒåŸºäº vLLMï¼ˆæ¨ç†åŠ é€Ÿï¼‰å’Œ TEIï¼ˆå‘é‡åŠ é€Ÿï¼‰æ„å»ºï¼Œå……åˆ†å‘æŒ¥å•å¡ 24G æ˜¾å­˜æ€§èƒ½ï¼Œå®ç°é«˜å¹¶å‘ã€ä½å»¶è¿Ÿçš„çŸ¥è¯†åº“é—®ç­”ã€‚

### æ ¸å¿ƒç‰¹æ€§
- ğŸ‡¨ğŸ‡³ å›½å†…ç½‘ç»œä¼˜åŒ–
- âš¡ é«˜æ€§èƒ½æ¨ç†
- ğŸ’¾ æ˜¾å­˜ç²¾ç»†ç®¡ç†
- ğŸŒ FRP + Nginx å…¬ç½‘è®¿é—®æ–¹æ¡ˆ

## ğŸ› ï¸ æŠ€æœ¯æ ˆ
- FastGPT + MongoDB + PostgreSQL
- vLLM (Qwen2.5-7B)
- TEI (BGE-M3)
- FRP + Nginx
- Docker & Docker Compose

## âš¡ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè¦æ±‚
- Ubuntu 20.04 / 22.04
- CUDA 12.1+
- æ˜¾å­˜ â‰¥ 24GB

### 2. å›½å†…åŠ é€Ÿæ¨¡å‹ä¸‹è½½

```bash
pip install huggingface_hub
export HF_ENDPOINT=https://hf-mirror.com

# Qwen2.5
huggingface-cli download --resume-download Qwen/Qwen2.5-7B-Instruct \
  --local-dir /your/path/Qwen2.5

# BGE-M3
huggingface-cli download --resume-download BAAI/bge-m3 \
  --local-dir /your/path/bge-m3 \
  --exclude "*.DS_Store"

