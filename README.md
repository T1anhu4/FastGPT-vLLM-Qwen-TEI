<div align="right">
  <a href="README_EN.md">ğŸŒ English Version</a>
</div>

# ğŸš€FastGPT-vLLM-Qwen-TEIå…¨é“¾è·¯æœ¬åœ°åŒ–éƒ¨ç½²

> åŸºäºvLLM(Qwen2.5)çš„FastGPTé«˜æ€§èƒ½ç§æœ‰RAGçŸ¥è¯†åº“å’ŒFrp+Nginxå…¬ç½‘è®¿é—®çš„ä¸€ç«™å¼éƒ¨ç½²æ–¹æ¡ˆã€‚
> ä¸“ä¸ºå›½å†…å†…ç½‘ç¯å¢ƒä¼˜åŒ–ï¼Œè§£å†³HuggingFaceä¸‹è½½ã€Dockeré•œåƒåŠ é€ŸåŠæ˜¾å­˜OOMç­‰ç—›ç‚¹ã€‚

![FastGPT](https://img.shields.io/badge/FastGPT-v4.x-blue)
![vLLM](https://img.shields.io/badge/vLLM-0.6.x-green)
![Qwen](https://img.shields.io/badge/Model-Qwen2.5--7B-violet)
![TEI](https://img.shields.io/badge/Embedding-BGE--M3-orange)

## ğŸ“–é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æä¾›äº†ä¸€å¥—å®Œæ•´çš„FastGPTæœ¬åœ°åŒ–éƒ¨ç½²å®æˆ˜æŒ‡å—ï¼ŒåŸºäºvLLMï¼ˆæ¨ç†åŠ é€Ÿï¼‰å’ŒTEIï¼ˆå‘é‡åŠ é€Ÿï¼‰æ„å»ºï¼Œå……åˆ†å‘æŒ¥å•å¡æ˜¾å­˜æ€§èƒ½ï¼Œå®ç°é«˜å¹¶å‘ã€ä½å»¶è¿Ÿçš„çŸ¥è¯†åº“é—®ç­”ã€‚

### æ ¸å¿ƒç‰¹æ€§
- ğŸ‡¨ğŸ‡³ **å›½å†…ç½‘ç»œä¼˜åŒ–**ï¼šæä¾›HuggingFaceé•œåƒä¸‹è½½ã€Dockeré•œåƒä»£ç†é…ç½®å…¨æµç¨‹ã€‚
- âš¡ **é«˜æ€§èƒ½æ¨ç†**ï¼šä½¿ç”¨vLLMéƒ¨ç½²Qwen2.5-7Bï¼Œä½¿ç”¨TEIéƒ¨ç½²BGE-M3ã€‚
- ğŸ’¾ **æ˜¾å­˜ç²¾ç»†ç®¡ç†**ï¼šé€šè¿‡å‚æ•°è°ƒä¼˜ï¼Œå®ç°LLMä¸Embeddingæ¨¡å‹åœ¨å•å¡æ˜¾å­˜ä¸‹çš„ç¨³å®šå…±å­˜ã€‚
- ğŸŒ **å…¬ç½‘è®¿é—®**ï¼šé›†æˆFRP + Nginxæ–¹æ¡ˆï¼Œå®ç°å†…ç½‘æœåŠ¡çš„å…¬ç½‘å®‰å…¨è®¿é—®ã€‚

## ğŸ› ï¸æŠ€æœ¯æ ˆ
- **åº”ç”¨å±‚**ï¼šFastGPT + MongoDB + PostgreSQL(pgvector)
- **æ¨ç†å±‚**ï¼švLLM(Qwen2.5-7B-Instruct)
- **ç´¢å¼•å±‚**ï¼šText Embeddings Inference(BAAI/bge-m3)
- **ç½‘ç»œå±‚**ï¼šFRP(å†…ç½‘ç©¿é€) + Nginx(åå‘ä»£ç†)
- **å®¹å™¨åŒ–**ï¼šDocker & Docker Compose

## âš¡å¿«é€Ÿå¼€å§‹

## 1. ç¯å¢ƒæ­å»º
ä»¥ä¸‹æ˜¯æˆ‘ä¸ªäººéƒ¨ç½²çš„æœºå™¨é…ç½®å’Œç¯å¢ƒï¼š
- Ubuntu 22.04
- CUDA 12.1
- RTX3090 24GB
- Python 3.10
- Docker 28.2.2
- Dcoker Compose 2.20.3

### 1.1 å®‰è£…NVIDIAé©±åŠ¨ä¸CUDA
ç¡®ä¿`nvidia-smi`å¯ä»¥æ­£å¸¸è¾“å‡ºæ˜¾å¡ä¿¡æ¯ã€‚æ¨èå®‰è£…CUDA 12.1æˆ–ä»¥ä¸Šç‰ˆæœ¬ã€‚
è¯¦ç»†çš„å®‰è£…æ•™ç¨‹å¯ä»¥è‡ªè¡Œæœç´¢ï¼Œæœ¬é¡¹ç›®ä¸è¿‡å¤šä»‹ç»ã€‚

### 1.2 å®‰è£…Dockerä¸NVIDIA Container Toolkit
- æ³¨æ„ï¼šå¿…é¡»å®‰è£…`NVIDIA Container Toolkit`ï¼Œå¦åˆ™Dockerå®¹å™¨æ— æ³•è°ƒç”¨æ˜¾å¡ã€‚

```bash
# 1. å®‰è£…Docker
curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun
systemctl enable --now docker

curl -L https://github.com/docker/compose/releases/download/v2.20.3/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose

# éªŒè¯å®‰è£…
docker -v
docker-compose -v
# å¦‚å¤±æ•ˆï¼Œå¯ä»¥é—®AIè§£å†³ä¸‹~

# 2. é…ç½®å›½å†…é•œåƒæº(å…³é”®ï¼šJSONæ•°ç»„æœ«å°¾ä¸¥ç¦é€—å·)
sudo tee /etc/docker/daemon.json <<EOF
{
    "registry-mirrors": [
        "[https://docker.nju.edu.cn](https://docker.nju.edu.cn)",
        "[https://docker.m.daocloud.io](https://docker.m.daocloud.io)"
    ]
}
EOF

# 3. å®‰è£…NVIDIA Container Toolkit
sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo nvidia-ctk runtime configure --runtime=docker

# 4. é‡å¯Docker
sudo systemctl daemon-reload
sudo systemctl restart docker
```

### 1.3 å®‰è£…Pythonç¯å¢ƒ
- æ³¨æ„ï¼šæœ¬é¡¹ç›®ä½¿ç”¨çš„æ˜¯`Miniforge`å®‰è£…çš„è™šæ‹Ÿç¯å¢ƒï¼Œå½“ç„¶ä½ ä¹Ÿå¯ä»¥ä¸ç”¨è™šæ‹Ÿç¯å¢ƒï¼Œç”¨ä½ è‡ªå·±çš„æœ¬åœ°Pythonç¯å¢ƒä¹Ÿè¡Œï¼Œè‡ªè¡Œé€‰æ‹©~
```bash
# åˆ›å»ºå¹¶æ¿€æ´»ç¯å¢ƒ
conda create -n llm python=3.10
conda activate llm

# å®‰è£…ä¾èµ–
pip install vllm huggingface_hub
```

## 2. æ¨¡å‹ä¸‹è½½

```bash
pip install huggingface_hub
export HF_ENDPOINT=https://hf-mirror.com

# Qwen2.5, å°†'/your/path/'åˆ‡æ¢æˆä½ æƒ³è¦ä¸‹è½½çš„è·¯å¾„
huggingface-cli download --resume-download Qwen/Qwen2.5-7B-Instruct \
  --local-dir /your/path/Qwen2.5 

# BGE-M3, å°†'/your/path/'åˆ‡æ¢æˆä½ æƒ³è¦ä¸‹è½½çš„è·¯å¾„
huggingface-cli download --resume-download BAAI/bge-m3 \
  --local-dir /your/path/bge-m3 \
  --exclude "*.DS_Store"
```

## 3.å¯åŠ¨æœ¬åœ°æ¨¡å‹æœåŠ¡
### 3.1å¯åŠ¨vLLM(Qwen2.5)
- æ³¨æ„ï¼šæœ¬é¡¹ç›®ä¸ºäº†ä¿è¯å•å¡24Gæ˜¾å­˜èƒ½å¤ŸåŒæ—¶è¿è¡ŒEmbeddingæ¨¡å‹ï¼Œæˆ‘å°†vLLMçš„æ˜¾å­˜åˆ©ç”¨ç‡ä¸¥æ ¼é™åˆ¶åœ¨80%ï¼Œå®é™…å¯æ ¹æ®è‡ªå·±æ˜¾å¡çš„æ˜¾å­˜æ¥è°ƒæ•´è¿™ä¸ªæ¯”ä¾‹ã€‚
- `--served-model-name Qwen2.5`: å…³é”®å‚æ•°ï¼Œå¼ºåˆ¶æŒ‡å®šæ¨¡å‹åç§°ï¼Œé˜²æ­¢FastGPTæŠ¥é”™404ã€‚
- `--gpu-memory-utilization 0.8`: é¢„ç•™çº¦20%æ˜¾å­˜ç»™TEIæ¨¡å‹ä½¿ç”¨ã€‚
```bash
# å°†/your/path/Qwen2.5æ›¿æ¢ä¸ºåˆšåˆšä¸‹è½½å¥½çš„æ¨¡å‹è·¯å¾„
python -m vllm.entrypoints.openai.api_server \
    --model /your/path/Qwen2.5 \
    --served-model-name Qwen2.5 \
    --max-model-len 8192 \
    --gpu-memory-utilization 0.8 \
    --port 8000 \
    --host 0.0.0.0 \
    --api-key sk-123456
```

### 3.2 å¯åŠ¨TEI(BGE-M3)
- æ³¨æ„ï¼šæœ¬é¡¹ç›®ä½¿ç”¨DockeræŒ‚è½½æœ¬åœ°æ¨¡å‹ç›®å½•ï¼Œå½»åº•è§„é¿å®¹å™¨å†…ä¸‹è½½å¤±è´¥çš„é—®é¢˜ã€‚
```bash
# å°†/your/path/bge-m3æ›¿æ¢ä¸ºåˆšåˆšä¸‹è½½å¥½çš„æ¨¡å‹è·¯å¾„
# ä½¿ç”¨m.daocloud.ioä»£ç†ghcr.ioé•œåƒ
sudo docker run --gpus all -d --name tei-bge \
    -p 8008:80 \
    -v /your/path/bge-m3:/data \
    m.daocloud.io/ghcr.io/huggingface/text-embeddings-inference:latest \
    --model-id /data
```

## 4.éƒ¨ç½²FastGPT
### 4.1 åˆ›å»ºç›®å½•ä¸æ‹‰å–é…ç½®æ–‡ä»¶
- ä»¥ä¸‹ä¸¤ä¸ªé•œåƒè‡ªè¡Œé€‰æ‹©ä¸‹è½½,è‹¥æ— æ³•ä¸‹è½½å¯ä»¥åœ¨æœ¬ä»“åº“ä¸­æ‰‹åŠ¨ä¸‹è½½ã€‚
- `docker-compose.yml`å’Œ`config.json`æ–‡ä»¶æˆ‘å·²ç»ä¸Šä¼ åœ¨æœ¬ä»“åº“äº†ã€‚
```bash
# å›½å†…é•œåƒ(é˜¿é‡Œäº‘)
bash <(curl -fsSL https://doc.fastgpt.cn/deploy/install.sh) --region=cn --vector=pg

# éå›½å†…é•œåƒ(dockhub, ghcr)
bash <(curl -fsSL https://doc.fastgpt.cn/deploy/install.sh) --region=global --vector=pg
```

### 4.2 ä¿®æ”¹é…ç½®æ–‡ä»¶(å¯é€‰)
- é€šå¸¸æƒ…å†µä¸‹ï¼Œ`docker-compose.yml`æ— éœ€ä¿®æ”¹ã€‚å¦‚æœç«¯å£å†²çªï¼Œå¯ä¿®æ”¹`ports`æ˜ å°„ã€‚
- `config.json`ç”¨äºç³»ç»Ÿçº§é…ç½®ï¼Œå»ºè®®ä¿æŒé»˜è®¤ï¼Œæ¨¡å‹é…ç½®æˆ‘ä»¬åœ¨Webç•Œé¢è¿›è¡Œã€‚
- æœ¬é¡¹ç›®çš„ä¿®æ”¹å¦‚ä¸‹ï¼š
`docker-compose.yml`
```bash
# è¿™ä¸ªè®¾ç½®æˆè‡ªå·±æœåŠ¡å™¨çš„å…¬ç½‘IPå°±è¡Œï¼Œç«¯å£ä¸å˜
S3_EXTERNAL_BASE_URL: http://123.456.789.112:7002

# fastgptè¿™é‡ŒåŠ äº†extra_hosts
...
fastgpt:
    container_name: fastgpt
    image: registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt:v4.14.3 # git
    ports:
     - 3000:3000
    networks:
      - fastgpt
    # æ·»åŠ äº†extra_hosts
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - mongo
      - sandbox
      - vectorDB
...

# fastgpt-mcp-serveré‡Œä¹ŸåŠ äº†extra_hosts
...
fastgpt-mcp-server:
    container_name: fastgpt-mcp-server
    image: registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt-mcp_server:v4.14.3
    networks:
     - fastgpt
    ports:
     - 3005:3000
    # æ·»åŠ äº†extra_hosts
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: always
...
```

`config.json`
```bash
# è¿™ä¸ªè®¾ç½®æˆè‡ªå·±æœåŠ¡å™¨çš„å…¬ç½‘IPå°±è¡Œï¼Œç«¯å£ä¸å˜
...
  "mcpServerProxyEndpoint": "http://123.456.789.112:7003"
...
```

### 4.3 å¯åŠ¨FastGPT
```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡(Mongo, Postgres, FastGPT, OneAPI)
docker-compose up -d
```
- è®¿é—®åœ°å€ï¼š`http://localhost:3000`(é»˜è®¤è´¦å·:`root`, å¯†ç :`docker-compose.yml`é‡Œçš„`DEFAULT_ROOT_PSW`)
- å®˜æ–¹é»˜è®¤å¯†ç æˆ‘è®°å¾—æ˜¯`1234`

### 4.4 é…ç½®æ¨¡å‹æ¸ é“
è¿›å…¥FastGPT -> è´¦å· -> æ¨¡å‹æä¾›å•† -> æ¨¡å‹æ¸ é“ -> æ–°å»ºæ¸ é“ï¼š
1.Qwen2.5é…ç½®ï¼š
- æ¸ é“åï¼šæƒ³å†™å•¥å†™å•¥
- åè®®ç±»å‹ï¼š`OpenAI`
- æ¨¡å‹ï¼š`æ–°å¢æ¨¡å‹` -> `è¯­è¨€æ¨¡å‹`
- æ¨¡å‹IDï¼š`Qwen2.5`(è¿™ä¸ªä¹Ÿåœ¨vLLMå¯åŠ¨å‘½ä»¤é‡Œå¯ä»¥è‡ªè¡Œè®¾ç½®)
- æ¨¡å‹æä¾›å•†ï¼š`é€šä¹‰åƒé—®`
- åˆ«åï¼šæƒ³å†™å•¥å†™å•¥
- æœ€å¤§ä¸Šä¸‹æ–‡ï¼š`12288`
- çŸ¥è¯†åº“æœ€å¤§å¼•ç”¨ï¼š`10000`
- æœ€å¤§å“åº”tokensï¼š`2048`
- å³ä¾§åŠŸèƒ½å¼€å…³ï¼šâœ…å·¥å…·è°ƒç”¨ âœ…çŸ¥è¯†åº“å¤„ç† âœ…é—®é¢˜åˆ†ç±» âœ…æ–‡æœ¬æå– âœ…å·¥å…·è°ƒç”¨èŠ‚ç‚¹(å¯ä»¥æŒ‰ç…§è‡ªå·±çš„éœ€æ±‚æ¥è®¾ç½®)
- è®¾ç½®å®Œæ¨¡å‹ç‚¹å‡»`ç¡®è®¤`åé€‰æ‹©`Qwen2.5`æ¨¡å‹
- ä»£ç†åœ°å€ï¼š`http://172.17.0.1:8000/v1`(å®¿ä¸»æœºç½‘å…³IP)
- APIå¯†é’¥ï¼š`sk-123456`(è¿™ä¸ªåœ¨ä½¿ç”¨vLLMå¯åŠ¨æ¨¡å‹æ—¶å¯è‡ªè¡Œè®¾ç½®ï¼Œè‹¥å¯åŠ¨å‘½ä»¤æ²¡è®¾ç½®åˆ™æ­¤æ å¯ä»¥éšä¾¿å¡«)

2.BGE-M3é…ç½®ï¼š
- æ¸ é“åï¼šæƒ³å†™å•¥å†™å•¥
- åè®®ç±»å‹ï¼š`OpenAI`
- æ¨¡å‹ï¼š`æ–°å¢æ¨¡å‹` -> `ç´¢å¼•æ¨¡å‹`
- æ¨¡å‹IDï¼š`BAAI/bge-m3`(è¿™ä¸ªä¹Ÿåœ¨vLLMå¯åŠ¨å‘½ä»¤é‡Œå¯ä»¥è‡ªè¡Œè®¾ç½®)
- æ¨¡å‹æä¾›å•†ï¼š`OpenAI`
- åˆ«åï¼šæƒ³å†™å•¥å†™å•¥
- âœ… å½’ä¸€åŒ–å¤„ç†
- å¹¶å‘è¯·æ±‚æ•°ï¼š`5`
- é»˜è®¤åˆ†å—é•¿åº¦ï¼š`512`
- æœ€å¤§ä¸Šä¸‹æ–‡ï¼š`8192`
- è®¾ç½®å®Œæ¨¡å‹ç‚¹å‡»`ç¡®è®¤`åé€‰æ‹©`BAAI/bge-m3`æ¨¡å‹
- ä»£ç†åœ°å€ï¼š`http://172.17.0.1:8000/v1`(å®¿ä¸»æœºç½‘å…³IP)
- APIå¯†é’¥ï¼š`sk-aaabbb`(æˆ‘è¿™é‡Œå¯åŠ¨æ—¶æ²¡è®¾ç½®ï¼Œæ‰€ä»¥éšä¾¿å¡«äº†)

éƒ½é…ç½®å®Œåå¯ä»¥åˆ†åˆ«å¯¹è¿™ä¸¤ä¸ªæ¨¡å‹è¿›è¡Œ`æ¨¡å‹æµ‹è¯•`ä¸‹ï¼Œæµ‹è¯•ä¸‹æ˜¯å¦æ­£å¸¸
æ­£å¸¸çš„è¯å¯ä»¥è¿›è¡Œä¸‹ä¸€æ­¥äº†ï¼Œæœ‰å¼‚å¸¸çš„è¯ç”¨curlç­‰å·¥å…·æ£€æŸ¥ä¸‹ç½‘ç»œé€šä¿¡æ˜¯å¦æ­£å¸¸(Dockerä¸å®¿ä¸»æœºçš„é€šä¿¡æ˜¯å¦æ­£å¸¸ï¼Œé€šå¸¸éƒ½æ˜¯é˜²ç«å¢™æ‹¦æˆªäº†)

## 5.å…¬ç½‘è®¿é—®(FRP + Nginx)
### 5.1 ä¸‹è½½frps
- æ³¨ï¼šäº‘æœåŠ¡å™¨å’Œæœ¬åœ°å®¢æˆ·ç«¯éƒ½è¦ä¸‹è½½è§£å‹è¿™ä¸ªåŒ…
```bash
# åˆ›å»ºä¸ªæ–‡ä»¶å¤¹æ”¾frpæ–‡ä»¶
mkdir ./frp && cd ./frp

# ä¸‹è½½frpåŒ…
wget https://github.com/fatedier/frp/releases/download/v0.65.0/frp_0.65.0_linux_amd64.tar.gz

# è§£å‹
tar -zxvf frp_0.65.0_linux_amd64.tar.gz
```

### 5.2 é…ç½®äº‘æœåŠ¡å™¨ç«¯(frps)
åœ¨å½“å‰`frp`ç›®å½•ä¸‹`nano ./frps.ini`è¿›è¡Œé…ç½®:
```bash
[common]
# frpsä¸frpcé€šä¿¡çš„ç«¯å£(è¦å’Œä½ frpc.iniçš„server_portä¸€è‡´)
bind_port = 7000
bind_addr = 0.0.0.0
# æ—¥å¿—è·¯å¾„
log_file = ./frps.log   
log_level =info
# æ—¥å¿—æœ€å¤§ä¿å­˜å¤©æ•°
log_max_days = 7        

# !!!å¼ºå¯†ç ,è¿™ä¸ªtokenå¯ä»¥è‡ªå·±å»éšæœºç”Ÿæˆä¸€ä¸ª,ä¸frpcç«¯å¿…é¡»ä¸€è‡´
authentication_method = token
token = 8f7d6c5b4a3e2d1c9b8a7f6e5d4c3b2a

# å¯ç”¨TLS - å¿…é¡»
tls_enable = true
```
é…ç½®å®Œæˆä¿å­˜åå°±å¯ä»¥å¯åŠ¨frpsæœåŠ¡äº†
```bash
./frps -c ./frps.ini
```

### 5.3 é…ç½®æœ¬åœ°å®¢æˆ·ç«¯(frpc)
åœ¨å½“å‰`frp`ç›®å½•ä¸‹`nano ./frpc.ini`è¿›è¡Œé…ç½®:
```bash
[common]
# å¡«å†™ä½ çš„äº‘æœåŠ¡å™¨å…¬ç½‘IP
server_addr = æ­¤å¤„å¡«å†™äº‘æœåŠ¡å™¨å…¬ç½‘IP
server_port = 7000
authentication_method = token
token = 8f7d6c5b4a3e2d1c9b8a7f6e5d4c3b2a

# å¯ç”¨TLS - å¿…é¡»
tls_enable = true

[fastgpt-app]
type = tcp
local_ip = 127.0.0.1
local_port = 3000
remote_port = 7001

[fastgpt-mcp]
type = tcp
local_ip = 127.0.0.1
local_port = 3005
remote_port = 7003

[fastgpt-s3]
type = tcp
local_ip = 127.0.0.1
local_port = 9000
remote_port = 7002
```
é…ç½®å®Œæˆä¿å­˜åå°±å¯ä»¥å¯åŠ¨frpsæœåŠ¡äº†
```bash
./frpc -c ./frpc.ini
```

### 5.4 å®‰å…¨ç»„å’Œé˜²ç«å¢™å¼€æ”¾
äº‘æœåŠ¡å™¨çš„å®‰å…¨ç»„å¾—å¼€æ”¾ä»¥ä¸‹å‡ ä¸ªç«¯å£:
`80` `7000` `7001` `7002` `7003`

äº‘æœåŠ¡å™¨å’Œæœ¬åœ°å®¢æˆ·ç«¯éƒ½å¾—å¼€æ”¾ä»¥ä¸Šå‡ ä¸ªç«¯å£ï¼š
```bash
sudo ufw allow 80/tcp
sudo ufw allow 7000/tcp
sudo ufw allow 7001/tcp
sudo ufw allow 7002/tcp
sudo ufw allow 7003/tcp

sudo ufw reload
```

### 5.5 é…ç½®Nginx
åœ¨äº‘æœåŠ¡å™¨ä¸Šæ–°å»ºä¸ªé…ç½®æ–‡ä»¶
```sudo nano /etc/nginx/conf.d/fastgpt.conf```

ç›´æ¥ç²˜è´´ï¼Œç„¶åå¯¹ä¸‰å¤„è¿›è¡Œä¿®æ”¹åœ°å€ï¼š
```bash
# 1. ä¸»åº”ç”¨, æ ¹æ®è‡ªå·±æœåŠ¡å™¨çš„å®é™…å…¬ç½‘IPè¿›è¡Œä¿®æ”¹
server {
    listen 80;
    server_name æ­¤å¤„ä¿®æ”¹ä¸ºä½ çš„æœåŠ¡å™¨å…¬ç½‘IP + ç«¯å£(ä¾‹å¦‚ï¼š123.456.789.112:7001);

    location / {
        proxy_pass http://127.0.0.1:7001;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        # WebSocketæ”¯æŒ(FastGPTæ‰“å­—æœºæ•ˆæœéœ€è¦)
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}

# 2. S3æ–‡ä»¶æœåŠ¡, æ ¹æ®è‡ªå·±æœåŠ¡å™¨çš„å®é™…å…¬ç½‘IPè¿›è¡Œä¿®æ”¹
server {
    listen 80;
    server_name æ­¤å¤„ä¿®æ”¹ä¸ºä½ çš„æœåŠ¡å™¨å…¬ç½‘IP + ç«¯å£(ä¾‹å¦‚ï¼š123.456.789.112:7002);

    # å…è®¸ä¸Šä¼ å¤§æ–‡ä»¶,è¿™ä¸ªå¤§å°è‡ªè¡Œè®¾ç½®
    client_max_body_size 1000m;

    location / {
        proxy_pass http://127.0.0.1:7002;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}

# 3. MCP æœåŠ¡, æ ¹æ®è‡ªå·±æœåŠ¡å™¨çš„å®é™…å…¬ç½‘IPè¿›è¡Œä¿®æ”¹
server {
    listen 80;
    server_name æ­¤å¤„ä¿®æ”¹ä¸ºä½ çš„æœåŠ¡å™¨å…¬ç½‘IP + ç«¯å£(ä¾‹å¦‚ï¼š123.456.789.112:7003);

    location / {
        proxy_pass http://127.0.0.1:7003;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}
```

ä¿å­˜å¥½åé‡å¯NginxæœåŠ¡ï¼š
```bash
sudo nginx -t
sudo systemctl reload nginx
```
ğŸ¤è´¡çŒ®
æ¬¢è¿æäº¤Issue
